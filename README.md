# Hands-Free AI Computer Control System

> **A sophisticated multimodal HCI system combining computer vision, embedded systems, and voice recognition for completely hands-free computer interaction.**

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![MediaPipe](https://img.shields.io/badge/MediaPipe-Face%20Mesh-green.svg)](https://mediapipe.dev/)
[![Arduino](https://img.shields.io/badge/Arduino-MPU6050-red.svg)](https://www.arduino.cc/)
[![ESP32](https://img.shields.io/badge/ESP32-I2S%20Audio-orange.svg)](https://www.espressif.com/)

---

## Table of Contents
- [Overview](#overview)
- [System Components](#system-components)
- [Control Panel & Study App](#control-panel--study-app)
- [Technical Solutions](#technical-solutions)
- [Key Features](#key-features)
- [Technical Stack](#technical-stack)

---

## Overview

This project is designed to help anyone who experiences difficulty using a traditional mouse due to precision challenges, accessibility needs, or ergonomic constraints. By leveraging computer vision, inertial sensors, and voice recognition, users can control their computer entirely through natural head movements and voice commands without requiring fine motor control.

The system achieves **sub-10ms latency** and **millimeter-precision** cursor control, making it practical for everyday computing tasks including web browsing, document editing, and application navigation.

### Who is this for?
- Users with limited hand mobility or dexterity challenges
- Individuals experiencing RSI (Repetitive Strain Injury) or carpal tunnel syndrome
- Anyone seeking an alternative to traditional mouse input
- Researchers exploring multimodal human-computer interaction

### What makes it unique?
This system combines three independent input modalities (face tracking, IMU sensors, and voice commands) to create a robust and fault-tolerant control interface that adapts to the user's natural movements rather than requiring precise gestures.

---

## System Components

### 1. Computer Vision Module (MediaPipe)
- **Purpose**: X-axis cursor control via facial landmark detection
- **Technology**: MediaPipe Face Mesh (478 3D landmarks)
- **Features**:
  - Head rotation detection for horizontal movement
  - Lip-purse gesture for precision mode (25% speed)
  - Mouth-pull detection for left/right click
  - Real-time processing at 60 FPS

### 2. IMU Sensor Module (Arduino + MPU-6050)
- **Purpose**: Y-axis cursor control via head tilt
- **Technology**: 6-axis accelerometer/gyroscope
- **Features**:
  - Two-phase calibration system (center point + range scan)
  - Exponential movement curves for natural feel
  - Smoothing algorithms to reduce jitter

### 3. Voice Control Module (ESP32 + I2S Microphone)
- **Purpose**: Hands-free command input for lock zones
- **Technology**: I2S digital microphone + Google Speech Recognition
- **Features**:
  - 16kHz audio sampling with 1.7s capture windows
  - Lock zone commands: "up", "down", "release"
  - Real-time audio streaming via USB serial
  - Auto-detection with voice activity detection (VAD)

---

## Control Panel & Study App

### Control Panel (PyQt6)
As a university student, accessing multiple platforms throughout the day can be time-consuming and tedious. The **Control Panel** simplifies this workflow by automating common tasks:

**Purpose**: Streamline access to frequently used platforms and tools

**Key Features**:
- **Automated Blackboard Access**: One-click login to university LMS, automatically navigates to your courses page without manual authentication
- **Gemini AI Integration**: Opens Gemini with automatic microphone activation, ready for voice interaction immediately
- **Quick Shortcuts**: Instant access to Gmail, YouTube, and the custom Study App
- **Smart Window Management**: Automatically positions windows in a 30/70 split-screen layout (Control Panel on left, browser on right)
- **Session Persistence**: Maintains browser tabs across sessions for seamless workflow continuation

**Student Benefit**: Instead of opening multiple browsers, logging into each platform separately, and managing window positions manually, everything is accessible in 2-3 clicks. This is particularly helpful when using hands-free control where traditional multitasking is more challenging.

### Smart Study Assistant

The **Smart Study Assistant** is a custom-built web application designed specifically for university students to streamline the study process using AI-powered tools.

**Purpose**: Transform study materials into interactive learning experiences

**Core Features**:

1. **Upload File**: 
   - Supports PDF, PowerPoint, TXT, and DOCX formats
   - Processes lecture notes, textbooks, and study materials
   - Simple drag-and-drop interface optimized for hands-free control

2. **Summarize**: 
   - Automatically generates concise summaries of uploaded content
   - Extracts key points and main concepts
   - Ideal for quick review before exams

3. **Generate Questions**: 
   - Creates practice questions from your study materials
   - Supports multiple-choice and conceptual questions
   - Includes answer verification with "Show Answer" functionality
   - Perfect for self-testing and exam preparation

4. **Export All**: 
   - Download summaries and questions in organized formats
   - Create portable study guides for offline review

5. **My Files**: 
   - Access previously uploaded materials and generated content
   - Track study progress across multiple subjects

**Student Workflow**:
Instead of manually reading through lengthy lecture slides, highlighting important points, and creating your own practice questions, the Study App automates this entire process. Upload your lecture PDFs, get instant summaries, test yourself with AI-generated questions, and export everything for reviewâ€”all through an interface designed to work seamlessly with hands-free control.

**Why this matters**: Traditional study workflows require constant switching between reading materials, note-taking apps, and question banks. This integrated approach reduces cognitive load and physical interaction, making studying more efficient and accessible.

---

## Technical Solutions

### Slow Mode (Precision Control)
Traditional mouse control requires fine motor skills to position the cursor precisely on small UI elements like buttons or links. This system solves this challenge with **Slow Mode**:

- **Activation**: Purse your lips together
- **Speed Reduction**: Cursor speed reduces to 25% of normal
- **Use Case**: Hovering over small buttons, links, or UI controls
- **Benefit**: No need for steady hands or precise muscle control

This allows users with tremors, limited dexterity, or accessibility needs to navigate interfaces that would otherwise be frustrating or impossible to use.

### Go Up/Down (Lock Zone Navigation)
Reaching the top and bottom edges of the screen typically requires significant head movement, which can be physically demanding or uncomfortable. The **Lock Zone System** solves this:

#### Top Lock ("Go Up")
- **Activation**: Say "up" or press `U`
- **Function**: Locks cursor to the top 5% of screen
- **Target Area**: Browser tabs, menu bars, window controls
- **Benefit**: Access top UI elements without tilting head upward

#### Bottom Lock ("Go Down")
- **Activation**: Say "down" or press `D`
- **Function**: Locks cursor to the bottom 5% of screen
- **Target Area**: Taskbar, system tray, docked applications
- **Benefit**: Access bottom UI elements without tilting head downward

#### Release
- **Activation**: Say "release" or press `R`
- **Function**: Returns cursor to saved position before lock
- **Benefit**: Quick return to working area

**Why this matters**: Without lock zones, users would need to crane their neck significantly to reach screen edges. Voice-activated locks allow natural, comfortable posture while maintaining full screen access.

---

## Key Features

### Multi-Modal Input
- **Face Tracking**: 478-point facial mesh for precise rotation detection
- **IMU Sensing**: Accelerometer-based vertical positioning
- **Voice Commands**: Natural language control for lock zones
- **Keyboard Fallback**: Traditional input for testing and override

### Intelligent Algorithms
- **Exponential Curves**: Small movements = precision, large movements = speed
- **Adaptive Smoothing**: Edge zones use slower smoothing for accuracy
- **Deadzone Detection**: Ignores micro-movements to prevent drift
- **Click Hold Logic**: 300ms gesture duration prevents accidental triggers

### Lock Zone System
- **Top/Bottom Anchoring**: Constrains cursor to 5% edge zones
- **Position Memory**: Auto-saves and restores cursor location
- **Multi-Input Control**: Accessible via voice, keyboard, or terminal

### Performance
- **Latency**: < 10ms end-to-end
- **Frame Rate**: 60 FPS camera + 100 Hz IMU updates
- **CPU Usage**: ~15% (Intel i5)
- **Memory**: ~200 MB

---

## Technical Stack

### Software
| Component | Technology |
|-----------|-----------|
| **Computer Vision** | MediaPipe Face Mesh, OpenCV |
| **GUI Framework** | PyQt6 with custom styling |
| **Browser Automation** | Selenium WebDriver (Edge) |
| **Voice Recognition** | Google Speech-to-Text API |
| **Serial Communication** | PySerial (115200/921600 baud) |
| **Cursor Control** | PyAutoGUI, PyGetWindow |

### Hardware
| Component | Model | Purpose |
|-----------|-------|---------|
| **Webcam** | 720p @ 60 FPS | Face tracking |
| **Arduino** | Uno R4 WiFi | IMU processing |
| **IMU Sensor** | MPU-6050 | Head tilt detection |
| **Microcontroller** | ESP32 | Audio capture |
| **Microphone** | INMP441 (I2S) | Voice input |

### Algorithms
- **Exponential Response Curves**: Natural acceleration (power: 1.8-2.0)
- **Exponential Moving Average**: Jitter reduction with configurable alpha
- **Asymmetric Feature Analysis**: Facial landmark distance ratios
- **Position Mapping**: Normalized sensor data to screen coordinates

---

<div align="center">

### If this project helped you, please give it a star!

**Built with care for accessibility and innovation**

</div>
